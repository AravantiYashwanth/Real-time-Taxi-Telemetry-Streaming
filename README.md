# ğŸš• Real-time Taxi Telemetry Streaming

### ğŸ“˜ Overview
**Real-time Taxi Telemetry Streaming** is an **end-to-end, serverless streaming data pipeline** built on **AWS**.  
It is designed to ingest, process, enrich, and analyze high-velocity taxi trip data in real time.

The pipeline captures simulated taxi GPS and trip events, enriches them with geographical context, and then **fans out** the processed data to multiple destinations:

1. ğŸŸ¢ **Low-Latency Operational Store** â€” Powers a **DynamoDB** table for real-time micro-billing lookups (e.g., â€œfetch fare for Trip ID `T0001`â€).  
2. ğŸ”µ **Analytical Data Warehouse** â€” Feeds **Amazon Redshift** for BI dashboards in **QuickSight** (analyzing trends, zones, and revenue).  
3. ğŸŸ£ **Raw Data Lake** â€” Archives unaltered streaming events in **Amazon S3** for long-term storage, auditing, and reprocessing.

---

## ğŸ—ï¸ Solution Architecture

Taxi Fleet (producer.py)  
â”‚   
â–¼   
Amazon Kinesis Data Stream (taxi-trip-stream)    
â”‚    
â”œâ”€â”€â–¶ Kinesis Data Firehose (taxi-raw-firehose)    
â”‚ â”‚    
â”‚ â””â”€â–¶ Amazon S3 (Raw Data Lake)    
â”‚ â””â”€â–¶ (Lifecycle Policy â†’ S3 Glacier)    
â”‚    
â–¼   
AWS Lambda (EnrichTripDataFunction)   
â”‚    
â”‚ â””â”€â–¶ Amazon Location Service (Reverse Geocoding)   
â”‚    
â–¼    
Amazon SQS (taxi-trip-processing-queue) â—€â”€â”€ (DLQ for failed messages)    
â”‚    
â–¼    
AWS Lambda (ProcessAndStoreFunction)    
â”‚    
â”‚ â””â”€â–¶ Fare Calculation Logic    
â”‚      
â”œâ”€â”€â–¶ Amazon DynamoDB (TaxiBilling Table)      
â”‚ â””â”€â–¶ Real-time micro-billing lookups         
â”‚        
â””â”€â”€â–¶ Kinesis Data Firehose (Lambda-Redshift-Firehouse)      
â–¼      
Amazon Redshift (Data Warehouse)      
â–¼    
Amazon QuickSight (BI Dashboards)



---

## âš™ï¸ Technologies Used

| Category | Technologies |
|-----------|--------------|
| **Data Ingestion** | Amazon Kinesis Data Streams |
| **Streaming & Buffering** | Kinesis Data Firehose, Amazon SQS |
| **Data Processing** | AWS Lambda (Python 3.12) |
| **Data Enrichment** | Amazon Location Service |
| **Operational Storage (NoSQL)** | Amazon DynamoDB |
| **Analytical Storage (DWH)** | Amazon Redshift Serverless |
| **Data Lake Storage** | Amazon S3 (Standard + Glacier) |
| **Data Visualization (BI)** | Amazon QuickSight |
| **Simulation & Testing** | Python, Boto3 |

---

## ğŸ”„ Pipeline Breakdown

### ğŸ”¹ Step 1: Data Ingestion (Kinesis Data Stream)
A **Python producer script (`producer.py`)** simulates a fleet of taxis, generating JSON trip events in real time.  
These are streamed to **Kinesis Data Stream (`taxi-trip-stream`)**, acting as the durable ingestion point for all telemetry data.

---

### ğŸ”¹ Step 2: Raw Data Archiving (Firehose â†’ S3)
A **Kinesis Data Firehose** (`taxi-raw-firehose`) continuously reads from the Kinesis stream, batching and compressing records before archiving them in **Amazon S3**.  
An **S3 Lifecycle Policy** automatically transitions old data to **Glacier**, ensuring low-cost archival.

---

### ğŸ”¹ Step 3: Real-Time Enrichment (Lambda + Location Service)
The **EnrichTripDataFunction** Lambda is triggered by Kinesis.  
For each event:
1. Parses and validates JSON input.  
2. Calls **Amazon Location Service** for reverse geocoding â€” converting GPS coordinates into a human-readable pickup zone (e.g., *â€œNampally, Hyderabadâ€*).  
3. Publishes the enriched event to an **SQS queue (`taxi-trip-processing-queue`)**.

---

### ğŸ”¹ Step 4: Decoupling with SQS
Using **Amazon SQS** introduces a buffer between Lambdas, preventing message loss during downstream failures.  
A **Dead-Letter Queue (DLQ)** captures problematic messages for debugging without halting the main pipeline.

---

### ğŸ”¹ Step 5: Processing & Fan-Out (Lambda)
The **ProcessAndStoreFunction** Lambda is triggered by the SQS queue.  
It performs:
- **Fare calculation logic** based on distance, extra charges, and trip zone.  
- **Fan-out distribution** â€” sending final enriched trip data to both:
  - **DynamoDB (TaxiBilling Table)** for operational analytics.  
  - **Kinesis Firehose (Lambda-Redshift-Firehouse)** for warehousing in Redshift.

---

### ğŸ”¹ Step 6: Operational Store (DynamoDB)
Stores finalized trip data with **millisecond latency** lookups.  
Each record is partitioned by `trip_id` and sorted by `pickup_datetime`, enabling applications to instantly retrieve fare summaries or payment details.

---

### ğŸ”¹ Step 7: Analytical Warehouse (Redshift)
The same Lambda streams enriched trip data via Firehose to **Amazon Redshift**.  
This serves as a **schema-on-write** data warehouse, enabling advanced analytics and SQL-based reporting.

---

### ğŸ”¹ Step 8: Visualization (QuickSight)
**Amazon QuickSight** connects directly to Redshift to create dashboards showing:
- Total revenue by pickup zone  
- Average fare vs. distance  
- Cash vs. Card payment breakdown  
- Heatmaps of popular pickup locations  
- Hourly ride distribution across the city  

---

## ğŸ§  Key Features

âœ… **Fully Serverless Architecture** â€” No servers to manage; scales automatically.  
âœ… **Dual Data Paths** â€” Low-latency operational and high-throughput analytical.  
âœ… **Real-Time Enrichment** â€” Converts GPS data into contextual location data.  
âœ… **Resilient Design** â€” SQS + DLQ ensure fault tolerance and zero data loss.  
âœ… **Multi-Destination Delivery** â€” Single stream drives DynamoDB, Redshift, and S3.  
âœ… **Lifecycle Management** â€” S3 Glacier reduces long-term storage costs.  

---

## âš”ï¸ Challenges & Solutions

| Challenge | Solution |
|------------|-----------|
| **Data Loss Risk (Lambda â†’ Lambda)** | Introduced **Amazon SQS** as a durable buffer between enrichment and processing. |
| **Poison Pill Messages** | Added a **Dead-Letter Queue (DLQ)** to automatically isolate bad records. |
| **Conflicting Data Needs (Latency vs. Throughput)** | Used **Fan-Out Pattern** â€” DynamoDB for fast key-value reads, Redshift for deep analytics. |
| **Dynamic Scaling During Spikes** | Leveraged **Kinesis auto-scaling** and **Lambda concurrency controls** for elasticity. |

---

## ğŸ“‚ Project Structure
Real-time-Taxi-Streaming/    
â”‚    
â”œâ”€â”€ producer.py # Simulates taxi fleet, streams data to Kinesis    
â”‚    
â”œâ”€â”€ lambda_functions/    
â”‚ â”œâ”€â”€ enrich_trip_data.py # Lambda 1: Kinesis â†’ Enrichment (Location) â†’ SQS    
â”‚ â””â”€â”€ process_and_store.py # Lambda 2: SQS â†’ Fare Calc â†’ DynamoDB & Firehose    
â”‚    
â”œâ”€â”€ sql/    
â”‚ â””â”€â”€ create_redshift_table.sql # DDL for Redshift table (enriched_trip_data)    
â”‚    
â””â”€â”€ README.md    

---

## ğŸ“Š Sample Redshift Query

```sql
-- Top 10 Most Profitable Pickup Zones
SELECT
  zone_name,
  COUNT(trip_id) AS total_trips,
  SUM(total_amount) AS total_revenue,
  AVG(fare_amount) AS average_fare
FROM enriched_trip_data
WHERE zone_name != 'Unknown'
GROUP BY zone_name
ORDER BY total_revenue DESC
LIMIT 10;
```

## ğŸ’¡ Learnings

- Building **event-driven, serverless streaming pipelines** on AWS.  
- Leveraging **Kinesis Data Streams** for high-throughput ingestion.  
- Applying the **Fan-Out Pattern** to serve both operational and analytical systems.  
- Implementing **decoupled microservice design** using **SQS** and **DLQs**.  
- Performing **real-time enrichment** via **AWS Lambda + Amazon Location Service**.  
- Understanding differences between **Schema-on-Write (Redshift)** and **Schema-on-Read (S3)**.  

---

## ğŸ§° Tools & Services

AWS Kinesis Data Streams â€¢ AWS Kinesis Data Firehose â€¢ AWS Lambda â€¢ Amazon SQS â€¢  
Amazon DynamoDB â€¢ Amazon Redshift Serverless â€¢ Amazon S3 â€¢ Amazon QuickSight â€¢  
Amazon Location Service â€¢ Python (Boto3)

---

## ğŸ Conclusion

This project demonstrates how to build a **real-time, resilient, and scalable data streaming system** using **AWS serverless technologies**.  
It transforms raw taxi telemetry into **two distinct, high-value data products**:

- âš¡ **An operational DynamoDB store** for instant fare retrievals.  
- ğŸ“Š **An analytical Redshift warehouse** for trend and performance insights.  

Together, they enable **end-to-end visibility** â€” from live operations to strategic decision-making â€” with **zero data loss** and **minimal latency**.  

---

## ğŸ‘¨â€ğŸ’» Author

**A. Yashwanth**  
Aspiring Data Engineer | Python & AWS Enthusiast  
ğŸ“§ [www.linkedin.com/in/yashwantharavanti](https://www.linkedin.com/in/yashwantharavanti)
